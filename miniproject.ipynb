{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project D7041E , Group 31\n",
    "\n",
    "## Jacob MÃ¶ller,  jacmll-9@student.ltu.se\n",
    "## Emil Wiklund, emiwik-9@student.ltu.se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This mini project were done to futher improve our skills in and understanding of using MLP (multi-layer-percepton neural network) for supervised learning. The project utalizes the familiar dataset MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loadning image data from MNIST of handwritten digits.\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "#loads 60k training images and 10k testing images (pre setting of this data load method)\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset  = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(dataset=test_dataset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAOi0lEQVR4nO3cfazX8//H8eenk4sutijlIsJZioZptWoWHYYystqaxoy2sJWZTa6nC1tmmYtGhpG5ZtNippYNieairBVZTSKLOV0SZovW5/fHd9/nD+XrvD7OJbfb5p/T+3E+r5PTufc+1btSrVarAQAR0amtDwBA+yEKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQK/CNt2rQpKpVK3HPPPc32Pt9+++2oVCrx9ttvN9v7hPZGFGg3nnzyyahUKvHRRx+19VFaxMKFC2PixIlRX18fXbt2jYEDB8a0adPi+++/b+ujQerc1geAf4urr746jjrqqLjsssuiX79+8cknn8S8efNi8eLFsWrVqujSpUtbHxFEAVrLggULoqGh4XdvGzJkSFxxxRXx3HPPxZVXXtk2B4Pf8O0jOpRffvklZsyYEUOGDIkePXpEt27d4owzzoilS5f+6eb++++PY489Nrp06RKjRo2KtWvX7nPN+vXrY8KECdGzZ884+OCDY+jQofHqq6/+5Xl+/vnnWL9+fWzfvv0vr/1jECIixo8fHxER69at+8s9tAZRoEP54Ycf4vHHH4+GhoaYM2dOzJo1K7Zt2xajR4+O1atX73P9008/HQ888EBcc801ceutt8batWvj7LPPji1btuQ1n376aYwYMSLWrVsXt9xyS9x7773RrVu3GDduXLz88sv/8zwrVqyIk046KebNm1fTx9PY2BgREYcddlhNe2huvn1Eh3LooYfGpk2b4sADD8y3XXXVVXHiiSfGgw8+GPPnz//d9Z9//nls2LAh+vbtGxERY8aMieHDh8ecOXPivvvui4iI6667Lvr16xcrV66Mgw46KCIipk6dGiNHjoybb745fzffEubMmRN1dXUxYcKEFnsNKOFOgQ6lrq4ug7B3797YuXNn7NmzJ4YOHRqrVq3a5/px48ZlECIihg0bFsOHD4/FixdHRMTOnTvjrbfeiosvvjh+/PHH2L59e2zfvj127NgRo0ePjg0bNsQ333zzp+dpaGiIarUas2bNKv5Ynn/++Zg/f35MmzYtTjjhhOI9tARRoMN56qmn4tRTT42DDz44evXqFb17945FixbFrl279rl2f19sBwwYEJs2bYqI/9xJVKvVmD59evTu3ft3/82cOTMiIrZu3drsH8O7774bkydPjtGjR8edd97Z7O8fauXbR3Qozz77bEyaNCnGjRsXN954Y/Tp0yfq6urirrvuio0bNxa/v71790ZExA033BCjR4/e7zX9+/f/W2f+ozVr1sRFF10UJ598cixYsCA6d/bLkPbDZyMdyoIFC6K+vj4WLlwYlUol3/7f39X/0YYNG/Z522effRbHHXdcRETU19dHRMQBBxwQ55xzTvMf+A82btwYY8aMiT59+sTixYuje/fuLf6aUMK3j+hQ6urqIiKiWq3m2z788MN4//3393v9K6+88rs/E1ixYkV8+OGHcf7550dERJ8+faKhoSEeffTR+Pbbb/fZb9u27X+ep+SvpDY2NsZ5550XnTp1itdffz169+79lxtobe4UaHeeeOKJWLJkyT5vv+666+LCCy+MhQsXxvjx4+OCCy6IL7/8Mh555JEYNGhQ/PTTT/ts+vfvHyNHjowpU6bE7t27Y+7cudGrV6+46aab8pqHHnooRo4cGaecckpcddVVUV9fH1u2bIn3338/vv7661izZs2fnnXFihVx1llnxcyZM//yD5vHjBkTX3zxRdx0002xfPnyWL58ef7Y4YcfHueee24TfnagZYkC7c7DDz+837dPmjQpJk2aFI2NjfHoo4/G66+/HoMGDYpnn302Xnrppf0+qO7yyy+PTp06xdy5c2Pr1q0xbNiwmDdvXhx55JF5zaBBg+Kjjz6KO+64I5588snYsWNH9OnTJwYPHhwzZsxoto/rv3G5++679/mxUaNGiQLtQqX62/twAP7V/JkCAEkUAEiiAEASBQCSKACQRAGA1OR/p/DbRwoA0PE05V8guFMAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGA1LmtDwAtoUePHsWbXr16FW/Gjh1bvLnwwguLNxERp59+equ81tKlS4s3/HO4UwAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQKpUq9Vqky6sVFr6LLBfEyZMKN7MmDGjeHPyyScXb5r4y6fNfP/998WbiRMnFm/eeOON4g2trymfr+4UAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQPBCPVtOzZ8+adsuXLy/eDBw4sHhTy+d4e38gXi127dpVvBk3blzx5p133ine8Pd4IB4ARUQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACB1busD0DEdcsghxZslS5bU9Fq1PNyutfz666/Fm++++66m1+revXvxpmvXrsWbHj16FG+6detWvKF9cqcAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYDkgXjUpL6+vngzZMiQFjhJ8/nqq6+KN7Nnzy7ezJ8/v3gTETFy5MjizbJly2p6rVK9e/duldeh5blTACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkqekUpMDDzywePPiiy+2wEn2b/Xq1cWbZ555pnjT2NhYvKlVt27dWu21Sv38889tfQSaiTsFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkD8SjJh988EGrbIDW5U4BgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgNS5rQ8ANM2uXbva+gh/qkePHm19BJqJOwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACB5Sip0ENOnT2/rI/ypzZs3t/URaCbuFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkDwQD1rZiBEjatqde+65xZtKpVLTa/Hv5U4BgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgDJA/GoSV1dXfGmoaGh+Q/SxjZv3ly8mT17dk2vVcvPebVaLd688847xZtly5YVb2if3CkAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACB5IF47deaZZ9a0mzdvXjOfZP8qlUrxZtCgQS1wkuZTy8e0Y8eO4k3Pnj2LN61p/fr1xZtOnfz+8p/C/0kAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKAKRKtVqtNunCGh4W9k/Ur1+/4s3kyZOLN9dff33xJiKia9euNe2o7aFue/fubYGTdDxvvvlm8eaSSy6p6bVqeQgh/9GUL/fuFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgOQpqYUGDhxYvFm0aFHx5vjjjy/e1KqxsbFVNkcccUTx5u/sStXyOd7EXz7sx65du2ravfDCC8Wb2267rXhT6/naM09JBaCIKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoApM5tfYC21L179+LNc889V7yp5eF2H3/8cfEmIuLNN98s3jz44IPFm+3btxdvrr322uJNRMSUKVOKN0cffXRNr9UaFi9eXNNu9+7dxZvx48fX9Frt2d69e9v6CP9o7hQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJD+1Q/E69u3b/Fm8ODBLXCSfW3atKmm3axZs4o3AwYMKN4sW7aseHPMMccUb1rTL7/8UryZO3du8eb2228v3kTU9iC4ww47rHhz2mmnFW9Wr15dvNmzZ0/xJiJi586dNe1oGncKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIlWq1Wm3ShZVKS5+l1U2aNKl4M3/+/OY/CM1ux44dxZuzzz67eLN27driDbSVpny5d6cAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYDUua0P0Jbee++94s3zzz9fvLn00kuLN/y/LVu2FG/Gjh1bvPFwO3CnAMBviAIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAFKlWq1Wm3RhpdLSZ+kQBgwYULyZMmVK8Wbq1KnFm4iIzp1b58G3jz32WPHmtddeq+m1Vq5cWbyp5cmq8E/XlC/37hQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJA8EA/gX8ID8QAoIgoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGA1LmpF1ar1ZY8BwDtgDsFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFANL/AZ9grqxUBYxqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One random data sample from the MNIST data set.\n"
     ]
    }
   ],
   "source": [
    "sample_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=True)\n",
    "images, labels = next(iter(sample_loader))\n",
    "\n",
    "image = images.squeeze().cpu().numpy()\n",
    "label= labels.item()\n",
    "\n",
    "plt.imshow(image, cmap='gray', extent=[0,14,14,0])\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"One random data sample from the MNIST data set.\")\n",
    "\n",
    "#kansek kan snacka om hur modellen ser ett sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=5):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            all_predictions.extend(predictions.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    return accuracy\n",
    "\n",
    "#trying to get the confusion to work\n",
    "def test_model_2(model):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_images = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            all_predictions.extend(predictions.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_images.extend(images)\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) #flatten the input\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)    \n",
    "        x = F.softmax(x, dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 974    0    0    1    0    2    0    1    2    0]\n",
      " [   0 1120    4    2    0    2    1    2    4    0]\n",
      " [   6    2  989   18    2    2    5    5    3    0]\n",
      " [   1    0    3  983    0    9    0    9    5    0]\n",
      " [   4    0    4    0  942    2    7    4    3   16]\n",
      " [   7    0    1   13    0  859    4    2    5    1]\n",
      " [   9    3    3    1    1   12  923    2    4    0]\n",
      " [   2    6   17    6    0    2    0  991    0    4]\n",
      " [   4    0    3   15    4    6    4    5  932    1]\n",
      " [   6    6    2   16   18   16    1    7    4  933]]\n",
      "Accuracy on the test set: 0.9646\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Define parameters\n",
    "input_size = 28 * 28\n",
    "hidden_size = 128\n",
    "output_size = 10\n",
    "learning_rate = 0.001\n",
    "#num_epochs = 100\n",
    "num_epochs = 10\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = MLPModel(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Test the model\n",
    "#accuracy = test_model(model)\n",
    "\n",
    "# Test the model with confusion\n",
    "accuracy = test_model_2(model)\n",
    "print(f\"Accuracy on the test set: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the confusion-matrix above the amount of correct prediction for a certain class is illustrated through the posistional indecies.\n",
    "\n",
    "In the first row (row = 0) the calss corresponds to the handwritten digit of the number 0, the first coloum we can see that 974 samples were correctly predicted compared with its lable.\n",
    "\n",
    "At index (i = 0 , j = 3) we can see that a sample with lable 0 was classified as the number 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
